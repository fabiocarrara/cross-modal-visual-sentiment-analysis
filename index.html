<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="The Emotions of the Crowd: Learning Image Sentiment from Tweets via Cross-modal Distillation">
  <meta name="keywords" content="Visual Sentiment Analysis, Cross-modal distillation, Dataset creation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The Emotions of the Crowd: Learning Image Sentiment from Tweets via Cross-modal Distillation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- More Research -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!--
        <a class="navbar-item" href="#">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a>
      -->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Related Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="http://www.t4sa.it">
            Twitter 4 Sentiment Analysis
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <header class="column has-text-centered">
          <h1 class="title is-1 publication-title">The Emotions of the Crowd</h1>
          <p class="title publication-title">Learning Image Sentiment from Tweets via Cross-modal Distillation</p>
          <p class="is-size-4 publication-awards">ECAI 2023</p>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/alessio-serra-8a21ba226">Alessio Serra</a><sup>1</sup>,
            </span>
            <span class="author-block">
              Fabio Carrara<sup>2</sup>,
            </span>
            <span class="author-block">
              Maurizio Tesconi<sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://fabriziofalchi.it">Fabrizio Falchi</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Universit√† di Pisa</span>
            <span class="author-block"><sup>2</sup><a href="https://www.isti.cnr.it/">ISTI CNR</a></span>
            <span class="author-block"><sup>3</sup><a href="https://www.iit.cnr.it/">IIT CNR</a></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ebooks.iospress.nl/doi/10.3233/FAIA230503"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2304.14942"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v="
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/fabiocarrara/cross-modal-visual-sentiment-analysis"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Models Link. -->
              <span class="link-block">
                <a href="https://github.com/fabiocarrara/cross-modal-visual-sentiment-analysis?tab=readme-ov-file#trained-models"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Models</span>
                  </a>
              </span>
              <!-- Dataset Link.
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
          -->
          </div>
        </header>
      </div>
    </div>
  </div>
</section>

<!-- Carousel.
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-1"></div>
        <div class="item item-2"></div>
      </div>
    </div>
  </div>
</section>
-->

<!-- Teaser. -->
<section class="hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="content has-text-justified">
      <div class="hero-body">
        <img src="./static/images/overview.png" alt="Method Overview" class="teaser-image"><br><br>
        <p class="subtitle has-text-centered">Our method boils down to the following three steps:
          <strong>Training Data Collection</strong>: We collect and deduplicate multimodal (text + images) data from public social media posts.
          <strong>Cross-modal Distillation</strong>: We perform cross-modal knowledge distillation from a frozen textual teacher model to a student visual model using coupled (text, images) samples.
          <strong>Evaluation Phase</strong>: We evaluate the trained visual model on visual-only sentiment analysis.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Trends and opinion mining in social media increasingly focus on
            novel interactions involving visual media, like images and short
            videos, in addition to text.
          </p>
          <p>
            In this work, we tackle the problem of visual sentiment analysis of
            social media images &mdash; specifically, the prediction of image
            sentiment polarity. While previous work relied on manually labeled
            training sets, we propose an automated approach for building
            sentiment polarity classifiers based on a cross-modal distillation
            paradigm; starting from scraped multimodal (text + images) data, we
            train a student model on the visual modality based on the outputs of
            a textual teacher model that analyses the sentiment of the
            corresponding textual modality.
          </p>
          <p>
            We applied our method to randomly collected images crawled from
            Twitter over three months and produced, after automatic cleaning, a
            weakly-labeled dataset of &sim;1.5 million images. Despite
            exploiting noisy labeled samples, our training pipeline produces
            classifiers showing strong generalization capabilities and
            outperforming the current state of the art on five manually labeled
            benchmarks for image sentiment polarity prediction.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
  </div>
</section>

<!-- Predictions. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Examples</h2>
        <div class="content has-text-justified">
          <div class="hero-body">
            <img src="./static/images/samples.png" alt="Step 2: Evaluation" class="teaser-image"><br><br>
            <caption>Cherry-picked examples of predictions of our best model (ViT-L/16) on the Twitter Dataset benchmark. The first two rows contain correctly classified images with positive and negative sentiment polarity, respectively. The third row contains negative-labeled samples misclassified as positives, and the last row contains positive-labeled ones misclassified as negatives. Note that several misclassified samples appear ambiguous even to a human labeler due to personal sensibility.</caption>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Concurrent Work.
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>
-->


<section class="section hero is-light" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{serra2023emotions,
  author    = {Serra, Alessio and Carrara, Fabio and Tesconi, Maurizio and Falchi, Fabrizio},
  editor       = {Kobi Gal and Ann Now{\'{e}} and Grzegorz J. Nalepa and Roy Fairstein and Roxana Radulescu},
  title        = {The Emotions of the Crowd: Learning Image Sentiment from Tweets via Cross-Modal Distillation},
  booktitle    = {{ECAI} 2023 - 26th European Conference on Artificial Intelligence, September 30 - October 4, 2023, Krak{\'{o}}w, Poland - Including 12th Conference on Prestigious Applications of Intelligent Systems ({PAIS} 2023)},
  series       = {Frontiers in Artificial Intelligence and Applications},
  volume       = {372},
  pages        = {2089--2096},
  publisher    = {{IOS} Press},
  year         = {2023},
  url          = {https://doi.org/10.3233/FAIA230503},
  doi          = {10.3233/FAIA230503},
}</code></pre>
  </div>
</section>

<section class="section" id="ack">
  <div class="container is-max-desktop content has-text-justified">
    <!-- Abstract. -->
    <h2 class="title">Acknowledgements</h2>
    <p>
      <a href="https://www.ai4media.eu/" target="_blank"><img src="./static/images/ai4media.jpg" alt="AI4Media Project Logo" width="200" style="padding: 0 35px;"></a>
      This work has received financial support from the European Union's Horizon 2020 Research & Innovation Programme under Grand agreement N. 951911 (AI4Media - A European Excellence Centre for Media, Society and Democracy).
    </p>
    <br>
    <p>
      <a href="https://www.sun-xr-project.eu/" target="_blank"><img src="./static/images/sun.png" alt="SUN Project Logo" width="200" style="padding: 0 10px;"></a>
      This work has received financial support by the Horizon Europe Research & Innovation Programme under Grant agreement N. 101092612 (Social and hUman ceNtered XR - SUN project).
    </p>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/fabiocarrara" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
